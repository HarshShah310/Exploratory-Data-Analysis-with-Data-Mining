{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb4bc4e",
   "metadata": {},
   "source": [
    "# Assignment 3 - Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69003b08",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f6c38",
   "metadata": {},
   "source": [
    "For the Third Assignment, we are going to be performing association rule mining with Apriori and FP-Growth algorithm.\n",
    "\n",
    "1. There are set of questions associated with each task for apriori and fp-growth respectively.\n",
    "2. The dataset used for whole assignment is same.\n",
    "3. Each Task is presenting a challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365b901",
   "metadata": {},
   "source": [
    "Simply run the blow cell to load the dataset.\n",
    "\n",
    "The dataset has 38765 rows of the purchase orders of people from the grocery stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ff383311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Member_number</th>\n",
       "      <th>Date</th>\n",
       "      <th>itemDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1808</td>\n",
       "      <td>21-07-2015</td>\n",
       "      <td>tropical fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2552</td>\n",
       "      <td>05-01-2015</td>\n",
       "      <td>whole milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2300</td>\n",
       "      <td>19-09-2015</td>\n",
       "      <td>pip fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1187</td>\n",
       "      <td>12-12-2015</td>\n",
       "      <td>other vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3037</td>\n",
       "      <td>01-02-2015</td>\n",
       "      <td>whole milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38760</th>\n",
       "      <td>4471</td>\n",
       "      <td>08-10-2014</td>\n",
       "      <td>sliced cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38761</th>\n",
       "      <td>2022</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>candy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38762</th>\n",
       "      <td>1097</td>\n",
       "      <td>16-04-2014</td>\n",
       "      <td>cake bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38763</th>\n",
       "      <td>1510</td>\n",
       "      <td>03-12-2014</td>\n",
       "      <td>fruit/vegetable juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38764</th>\n",
       "      <td>1521</td>\n",
       "      <td>26-12-2014</td>\n",
       "      <td>cat food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38765 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Member_number        Date        itemDescription\n",
       "0               1808  21-07-2015         tropical fruit\n",
       "1               2552  05-01-2015             whole milk\n",
       "2               2300  19-09-2015              pip fruit\n",
       "3               1187  12-12-2015       other vegetables\n",
       "4               3037  01-02-2015             whole milk\n",
       "...              ...         ...                    ...\n",
       "38760           4471  08-10-2014          sliced cheese\n",
       "38761           2022  23-02-2014                  candy\n",
       "38762           1097  16-04-2014               cake bar\n",
       "38763           1510  03-12-2014  fruit/vegetable juice\n",
       "38764           1521  26-12-2014               cat food\n",
       "\n",
       "[38765 rows x 3 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\harsh\\\\OneDrive\\\\Documents\\\\Summer'23\\\\CSE 5334 - DM\\\\Assignment\\\\Sheth_4934_Shah_7387_Tadivaka_2726_Assignment3\\\\summer2023Assignment3\\\\Batch1\\\\Data_batch1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0091d2ca",
   "metadata": {},
   "source": [
    "### Task A: 5 points\n",
    "\n",
    "1. Print details on data.\n",
    "2. Check unique items and modify items if found any misfit names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a5ca1669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38765, 3)\n",
      "   Member_number        Date   itemDescription\n",
      "0           1808  21-07-2015    tropical fruit\n",
      "1           2552  05-01-2015        whole milk\n",
      "2           2300  19-09-2015         pip fruit\n",
      "3           1187  12-12-2015  other vegetables\n",
      "4           3037  01-02-2015        whole milk\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38765 entries, 0 to 38764\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Member_number    38765 non-null  int64 \n",
      " 1   Date             38765 non-null  object\n",
      " 2   itemDescription  38765 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 908.7+ KB\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())\n",
    "# Display all the details about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "98b48de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Unique items in 'itemDescription': ['tropical fruit' 'whole milk' 'pip fruit' 'other vegetables' 'rolls/buns'\n",
      " 'pot plants' 'citrus fruit' 'beef' 'frankfurter' 'chicken' 'butter'\n",
      " 'fruit/vegetable juice' 'packaged fruit/vegetables' 'chocolate'\n",
      " 'specialty bar' 'butter milk' 'bottled water' 'yogurt' 'sausage'\n",
      " 'brown bread' 'hamburger meat' 'root vegetables' 'pork' 'pastry'\n",
      " 'canned beer' 'berries' 'coffee' 'misc. beverages' 'ham' 'turkey'\n",
      " 'curd cheese' 'red/blush wine' 'frozen potato products' 'flour' 'sugar'\n",
      " 'frozen meals' 'herbs' 'soda' 'detergent' 'grapes' 'processed cheese'\n",
      " 'fish' 'sparkling wine' 'newspapers' 'curd' 'pasta' 'popcorn'\n",
      " 'finished products' 'beverages' 'bottled beer' 'dessert' 'dog food'\n",
      " 'specialty chocolate' 'condensed milk' 'cleaner' 'white wine' 'meat'\n",
      " 'ice cream' 'hard cheese' 'cream cheese ' 'liquor' 'pickled vegetables'\n",
      " 'liquor (appetizer)' 'UHT-milk' 'candy' 'onions' 'hair spray'\n",
      " 'photo/film' 'domestic eggs' 'margarine' 'shopping bags' 'salt' 'oil'\n",
      " 'whipped/sour cream' 'frozen vegetables' 'sliced cheese' 'dish cleaner'\n",
      " 'baking powder' 'specialty cheese' 'salty snack' 'Instant food products'\n",
      " 'pet care' 'white bread' 'female sanitary products' 'cling film/bags'\n",
      " 'soap' 'frozen chicken' 'house keeping products' 'spread cheese'\n",
      " 'decalcifier' 'frozen dessert' 'vinegar' 'nuts/prunes' 'potato products'\n",
      " 'frozen fish' 'hygiene articles' 'artif. sweetener' 'light bulbs'\n",
      " 'canned vegetables' 'chewing gum' 'canned fish' 'cookware'\n",
      " 'semi-finished bread' 'cat food' 'bathroom cleaner' 'prosecco'\n",
      " 'liver loaf' 'zwieback' 'canned fruit' 'frozen fruits' 'brandy'\n",
      " 'baby cosmetics' 'spices' 'napkins' 'waffles' 'sauces' 'rum'\n",
      " 'chocolate marshmallow' 'long life bakery product' 'bags' 'sweet spreads'\n",
      " 'soups' 'mustard' 'specialty fat' 'instant coffee' 'snack products'\n",
      " 'organic sausage' 'soft cheese' 'mayonnaise' 'dental care'\n",
      " 'roll products ' 'kitchen towels' 'flower soil/fertilizer' 'cereals'\n",
      " 'meat spreads' 'dishes' 'male cosmetics' 'candles' 'whisky' 'tidbits'\n",
      " 'cooking chocolate' 'seasonal products' 'liqueur' 'abrasive cleaner'\n",
      " 'syrup' 'ketchup' 'cream' 'skin care' 'rubbing alcohol' 'nut snack'\n",
      " 'cocoa drinks' 'softener' 'organic products' 'cake bar' 'honey' 'jam'\n",
      " 'kitchen utensil' 'flower (seeds)' 'rice' 'tea' 'salad dressing'\n",
      " 'specialty vegetables' 'pudding powder' 'ready soups' 'make up remover'\n",
      " 'toilet cleaner' 'preservation products']\n",
      "\n",
      " Misfit: {'Instant food products', 'UHT-milk'}\n",
      "\n",
      " unique_items_updated: ['tropical fruit' 'whole milk' 'pip fruit' 'other vegetables' 'rolls/buns'\n",
      " 'pot plants' 'citrus fruit' 'beef' 'frankfurter' 'chicken' 'butter'\n",
      " 'fruit/vegetable juice' 'packaged fruit/vegetables' 'chocolate'\n",
      " 'specialty bar' 'butter milk' 'bottled water' 'yogurt' 'sausage'\n",
      " 'brown bread' 'hamburger meat' 'root vegetables' 'pork' 'pastry'\n",
      " 'canned beer' 'berries' 'coffee' 'misc. beverages' 'ham' 'turkey'\n",
      " 'curd cheese' 'red/blush wine' 'frozen potato products' 'flour' 'sugar'\n",
      " 'frozen meals' 'herbs' 'soda' 'detergent' 'grapes' 'processed cheese'\n",
      " 'fish' 'sparkling wine' 'newspapers' 'curd' 'pasta' 'popcorn'\n",
      " 'finished products' 'beverages' 'bottled beer' 'dessert' 'dog food'\n",
      " 'specialty chocolate' 'condensed milk' 'cleaner' 'white wine' 'meat'\n",
      " 'ice cream' 'hard cheese' 'cream cheese ' 'liquor' 'pickled vegetables'\n",
      " 'liquor (appetizer)' 'uht-milk' 'candy' 'onions' 'hair spray'\n",
      " 'photo/film' 'domestic eggs' 'margarine' 'shopping bags' 'salt' 'oil'\n",
      " 'whipped/sour cream' 'frozen vegetables' 'sliced cheese' 'dish cleaner'\n",
      " 'baking powder' 'specialty cheese' 'salty snack' 'instant food products'\n",
      " 'pet care' 'white bread' 'female sanitary products' 'cling film/bags'\n",
      " 'soap' 'frozen chicken' 'house keeping products' 'spread cheese'\n",
      " 'decalcifier' 'frozen dessert' 'vinegar' 'nuts/prunes' 'potato products'\n",
      " 'frozen fish' 'hygiene articles' 'artif. sweetener' 'light bulbs'\n",
      " 'canned vegetables' 'chewing gum' 'canned fish' 'cookware'\n",
      " 'semi-finished bread' 'cat food' 'bathroom cleaner' 'prosecco'\n",
      " 'liver loaf' 'zwieback' 'canned fruit' 'frozen fruits' 'brandy'\n",
      " 'baby cosmetics' 'spices' 'napkins' 'waffles' 'sauces' 'rum'\n",
      " 'chocolate marshmallow' 'long life bakery product' 'bags' 'sweet spreads'\n",
      " 'soups' 'mustard' 'specialty fat' 'instant coffee' 'snack products'\n",
      " 'organic sausage' 'soft cheese' 'mayonnaise' 'dental care'\n",
      " 'roll products ' 'kitchen towels' 'flower soil/fertilizer' 'cereals'\n",
      " 'meat spreads' 'dishes' 'male cosmetics' 'candles' 'whisky' 'tidbits'\n",
      " 'cooking chocolate' 'seasonal products' 'liqueur' 'abrasive cleaner'\n",
      " 'syrup' 'ketchup' 'cream' 'skin care' 'rubbing alcohol' 'nut snack'\n",
      " 'cocoa drinks' 'softener' 'organic products' 'cake bar' 'honey' 'jam'\n",
      " 'kitchen utensil' 'flower (seeds)' 'rice' 'tea' 'salad dressing'\n",
      " 'specialty vegetables' 'pudding powder' 'ready soups' 'make up remover'\n",
      " 'toilet cleaner' 'preservation products']\n"
     ]
    }
   ],
   "source": [
    "# Extracting unique items from the 'itemDescription' column and printing them.\n",
    "unique_items = df['itemDescription'].unique()\n",
    "print(f\"\\n Unique items in 'itemDescription': {unique_items}\")\n",
    "\n",
    "misfit_data = set()\n",
    "\n",
    "# Checking for misfit items in the unique items list.\n",
    "for item_lst in unique_items:\n",
    "    for item in item_lst.split(', '):\n",
    "        # Checking if the lowercase version of the item is not present in the unique_items list.\n",
    "        if item.lower() not in unique_items:\n",
    "            misfit_data.add(item)\n",
    "\n",
    "# If any misfit data is found, print it.\n",
    "if misfit_data:\n",
    "    print(\"\\n Misfit:\", misfit_data)\n",
    "\n",
    "# Lowercasing all the entries in the 'itemDescription' column of the DataFrame.\n",
    "df['itemDescription'] = df['itemDescription'].str.lower()\n",
    "unique_items_updated = df['itemDescription'].unique()\n",
    "print('\\n unique_items_updated:', unique_items_updated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052be437",
   "metadata": {},
   "source": [
    "### Task B: 7 points\n",
    "\n",
    "Create a list of lists with grouping on member number and the transaction date and store it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c81345ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Member_number        Date  \\\n",
      "0               1000  15-03-2015   \n",
      "1               1000  24-06-2014   \n",
      "2               1000  24-07-2015   \n",
      "3               1000  25-11-2015   \n",
      "4               1000  27-05-2015   \n",
      "...              ...         ...   \n",
      "14958           4999  24-01-2015   \n",
      "14959           4999  26-12-2015   \n",
      "14960           5000  09-03-2014   \n",
      "14961           5000  10-02-2015   \n",
      "14962           5000  16-11-2014   \n",
      "\n",
      "                                       Transaction Items  \n",
      "0      [sausage, whole milk, semi-finished bread, yog...  \n",
      "1                      [whole milk, pastry, salty snack]  \n",
      "2                         [canned beer, misc. beverages]  \n",
      "3                            [sausage, hygiene articles]  \n",
      "4                             [soda, pickled vegetables]  \n",
      "...                                                  ...  \n",
      "14958  [tropical fruit, berries, other vegetables, yo...  \n",
      "14959                             [bottled water, herbs]  \n",
      "14960                    [fruit/vegetable juice, onions]  \n",
      "14961       [soda, root vegetables, semi-finished bread]  \n",
      "14962                   [bottled beer, other vegetables]  \n",
      "\n",
      "[14963 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group the data based on 'Member_number' and 'Date'\n",
    "grouped_data = df.groupby(['Member_number', 'Date'])['itemDescription'].apply(list).reset_index(name='Transaction Items')\n",
    "\n",
    "# Print the DataFrame with grouped data\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea40165",
   "metadata": {},
   "source": [
    "### Task C: 7 points\n",
    "\n",
    "Transform the data having unique product as column name and indication of the product in the each transaction as 0/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "21c55d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sausage  whole milk  semi-finished bread  yogurt  pastry  salty snack  \\\n",
      "0        1           1                    1       1       0            0   \n",
      "1        0           1                    0       0       1            1   \n",
      "2        0           0                    0       0       0            0   \n",
      "3        1           0                    0       0       0            0   \n",
      "4        0           0                    0       0       0            0   \n",
      "\n",
      "   canned beer  misc. beverages  hygiene articles  soda  ...  decalcifier  \\\n",
      "0            0                0                 0     0  ...            0   \n",
      "1            0                0                 0     0  ...            0   \n",
      "2            1                1                 0     0  ...            0   \n",
      "3            0                0                 1     0  ...            0   \n",
      "4            0                0                 0     1  ...            0   \n",
      "\n",
      "   kitchen utensil  organic products  frozen chicken  salad dressing  \\\n",
      "0                0                 0               0               0   \n",
      "1                0                 0               0               0   \n",
      "2                0                 0               0               0   \n",
      "3                0                 0               0               0   \n",
      "4                0                 0               0               0   \n",
      "\n",
      "   specialty vegetables  toilet cleaner  rubbing alcohol  Member_number  \\\n",
      "0                     0               0                0           1000   \n",
      "1                     0               0                0           1000   \n",
      "2                     0               0                0           1000   \n",
      "3                     0               0                0           1000   \n",
      "4                     0               0                0           1000   \n",
      "\n",
      "         Date  \n",
      "0  15-03-2015  \n",
      "1  24-06-2014  \n",
      "2  24-07-2015  \n",
      "3  25-11-2015  \n",
      "4  27-05-2015  \n",
      "\n",
      "[5 rows x 169 columns]\n"
     ]
    }
   ],
   "source": [
    "# Applying lambda function on Transaction Items column and transforming dataframe into binary format\n",
    "transformed_data = grouped_data['Transaction Items'].apply(lambda x: pd.Series({item: 1 for item in x}))\n",
    "\n",
    "# Replacing NaN values with 0 and convert dataframe into integer types. \n",
    "transformed_data = transformed_data.fillna(0).astype(np.int8)\n",
    "transformed_data['Member_number'] = grouped_data['Member_number']\n",
    "transformed_data['Date'] = grouped_data['Date']\n",
    "\n",
    "print(transformed_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647cfa6",
   "metadata": {},
   "source": [
    "### Task D: 7 points\n",
    "\n",
    "Apply apriori algorithm with 0.001 support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a1a5c42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      support                                    itemsets\n",
      "0    0.060349                                   (sausage)\n",
      "1    0.157923                                (whole milk)\n",
      "2    0.009490                       (semi-finished bread)\n",
      "3    0.085879                                    (yogurt)\n",
      "4    0.051728                                    (pastry)\n",
      "..        ...                                         ...\n",
      "745  0.001136      (other vegetables, yogurt, whole milk)\n",
      "746  0.001002              (soda, rolls/buns, whole milk)\n",
      "747  0.001136        (soda, other vegetables, whole milk)\n",
      "748  0.001203  (other vegetables, rolls/buns, whole milk)\n",
      "749  0.001136        (soda, other vegetables, rolls/buns)\n",
      "\n",
      "[750 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori as apr\n",
    "\n",
    "transformed_data_f = transformed_data.astype(bool)\n",
    "\n",
    "#Applying the Apriori algorithm and generating frequent item sets with support 0.001\n",
    "frequent_itemsets_f = apr(transformed_data_f.drop(['Member_number', 'Date'], axis=1), min_support=0.001, use_colnames=True)\n",
    "\n",
    "print(frequent_itemsets_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edc1be5",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://medium.com/analytics-vidhya/association-analysis-in-python-2b955d0180c\n",
    "https://efficient-apriori.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27002f88",
   "metadata": {},
   "source": [
    "### Task E: 5 points\n",
    "\n",
    "Print top 5 association rules for lift metric and 1 threshold in accordance with support value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "aefe6c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               antecedents            consequents  antecedent support  \\\n",
      "214              (sausage)   (whole milk, yogurt)            0.060349   \n",
      "211   (whole milk, yogurt)              (sausage)            0.011161   \n",
      "212  (sausage, whole milk)               (yogurt)            0.008955   \n",
      "213               (yogurt)  (sausage, whole milk)            0.085879   \n",
      "166  (specialty chocolate)         (citrus fruit)            0.015973   \n",
      "\n",
      "     consequent support   support  confidence      lift  leverage  conviction  \\\n",
      "214            0.011161  0.001470    0.024363  2.182917  0.000797    1.013532   \n",
      "211            0.060349  0.001470    0.131737  2.182917  0.000797    1.082219   \n",
      "212            0.085879  0.001470    0.164179  1.911760  0.000701    1.093681   \n",
      "213            0.008955  0.001470    0.017121  1.911760  0.000701    1.008307   \n",
      "166            0.053131  0.001403    0.087866  1.653762  0.000555    1.038081   \n",
      "\n",
      "     zhangs_metric  \n",
      "214       0.576701  \n",
      "211       0.548014  \n",
      "212       0.481231  \n",
      "213       0.521727  \n",
      "166       0.401735  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Calculating association rules with a minimum lift of 1\n",
    "association_rules_df = association_rules(frequent_itemsets_f, metric=\"lift\", min_threshold=1)\n",
    "association_rules_df.sort_values(by='support', ascending=False, inplace=True)\n",
    "#Fetching top 5 association rules\n",
    "top_5_association_rules = association_rules_df.nlargest(5,'lift')\n",
    "\n",
    "print(top_5_association_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be446e",
   "metadata": {},
   "source": [
    "### Task F: 3 points\n",
    "\n",
    "Store the association rules from top to bottom with respect to lift parameter and store it in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f9d4a261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 antecedents              consequents  antecedent support  \\\n",
      "214                (sausage)     (whole milk, yogurt)            0.060349   \n",
      "211     (whole milk, yogurt)                (sausage)            0.011161   \n",
      "212    (sausage, whole milk)                 (yogurt)            0.008955   \n",
      "213                 (yogurt)    (sausage, whole milk)            0.085879   \n",
      "167           (citrus fruit)    (specialty chocolate)            0.053131   \n",
      "..                       ...                      ...                 ...   \n",
      "63                  (grapes)                   (soda)            0.014436   \n",
      "118           (citrus fruit)                   (beef)            0.053131   \n",
      "119                   (beef)           (citrus fruit)            0.033950   \n",
      "107  (fruit/vegetable juice)             (rolls/buns)            0.034017   \n",
      "106             (rolls/buns)  (fruit/vegetable juice)            0.110005   \n",
      "\n",
      "     consequent support   support  confidence      lift      leverage  \\\n",
      "214            0.011161  0.001470    0.024363  2.182917  7.967480e-04   \n",
      "211            0.060349  0.001470    0.131737  2.182917  7.967480e-04   \n",
      "212            0.085879  0.001470    0.164179  1.911760  7.012151e-04   \n",
      "213            0.008955  0.001470    0.017121  1.911760  7.012151e-04   \n",
      "167            0.015973  0.001403    0.026415  1.653762  5.548137e-04   \n",
      "..                  ...       ...         ...       ...           ...   \n",
      "63             0.097106  0.001403    0.097222  1.001195  1.674919e-06   \n",
      "118            0.033950  0.001804    0.033962  1.000349  6.297697e-07   \n",
      "119            0.053131  0.001804    0.053150  1.000349  6.297697e-07   \n",
      "107            0.110005  0.003743    0.110020  1.000136  5.091755e-07   \n",
      "106            0.034017  0.003743    0.034022  1.000136  5.091755e-07   \n",
      "\n",
      "     conviction  zhangs_metric  \n",
      "214    1.013532       0.576701  \n",
      "211    1.082219       0.548014  \n",
      "212    1.093681       0.481231  \n",
      "213    1.008307       0.521727  \n",
      "167    1.010726       0.417500  \n",
      "..          ...            ...  \n",
      "63     1.000129       0.001211  \n",
      "118    1.000012       0.000369  \n",
      "119    1.000020       0.000361  \n",
      "107    1.000017       0.000141  \n",
      "106    1.000005       0.000153  \n",
      "\n",
      "[240 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Sorting association rules wrt lift in descending order\n",
    "sorted_rules_by_lift = association_rules_df.sort_values(by='lift', ascending=False)\n",
    "\n",
    "# Storing the sorted association rules  in a variable\n",
    "top_association_rules = sorted_rules_by_lift\n",
    "\n",
    "print(top_association_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8651b2",
   "metadata": {},
   "source": [
    "### Task G: 10 points\n",
    "\n",
    "Understand this,\n",
    "- antecedent support: If X is called antecendent, 'antecedent support' computes the proportion of transactions that contain the antecedent X.\n",
    "- consequent support: If Y is called consequent, 'consequent support' computes the proportion of transactions that contain the antecedent Y.\n",
    "- support: 'support' computes the proportion of transactions that contain the antecedent X and Y.\n",
    "- confidence: Probability of buying Y when X is bought.\n",
    "- lift: Represents how many times the probability of getting Y increases when X is received.\n",
    "\n",
    "Define a function which takes the (sorted values from the association rules,a product name) and returns top recommendation list for that product name.\n",
    "\n",
    "Tip: the recommendated item are Consequents by matching the product antecedents as product to search for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a8072a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(association_rules, product_name):\n",
    "    top_n=5\n",
    "    # Filtering association rules where the product_name is in the antecedents\n",
    "    filtered_rules = association_rules[association_rules['antecedents'].apply(lambda x: product_name in x)]\n",
    "    sorted_filtered_rules = filtered_rules.sort_values(by='lift', ascending=False)\n",
    "\n",
    "    # Fetching top recommendation list for the product_name\n",
    "    recommendations = sorted_filtered_rules['consequents'].head(top_n).tolist()\n",
    "    recommendations = [set(items) for items in recommendations]\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386bdc61",
   "metadata": {},
   "source": [
    "### Task H: 5 points\n",
    "\n",
    "Print top 5 reccomendated items for product 'sausage'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d03702e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended items for 'sausage':\n",
      "[{'whole milk', 'yogurt'}, {'yogurt'}, {'whole milk'}, {'beverages'}, {'soda', 'whole milk'}]\n"
     ]
    }
   ],
   "source": [
    "product_name = 'sausage'\n",
    "top_recommendations = get_top_recommendations(sorted_rules_by_lift, product_name)\n",
    "\n",
    "print(f\"Top 5 recommended items for '{product_name}':\")\n",
    "print(top_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd63c3",
   "metadata": {},
   "source": [
    "### Task I: 5 points\n",
    "\n",
    "Print top 5 reccomendated items for product 'sausage' with 0.005 support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "98ab0731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended items for 'sausage':\n",
      "[{'yogurt'}, {'soda'}]\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets_f = apr(transformed_data_f.drop(['Member_number', 'Date'], axis=1), min_support=0.005, use_colnames=True)\n",
    "\n",
    "# Generate association rules from frequent itemsets\n",
    "association_rules_df = association_rules(frequent_itemsets_f, metric=\"lift\", min_threshold=1)\n",
    "soretd_association_rules_df = association_rules_df.sort_values(by='lift', ascending=False)\n",
    "\n",
    "\n",
    "#Get top 5 recommended items\n",
    "Product_name = 'sausage'\n",
    "top_5_recommended_items = get_top_recommendations(soretd_association_rules_df, product_name)\n",
    "\n",
    "print(f\"Top 5 recommended items for 'sausage':\")\n",
    "print(top_5_recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b895d",
   "metadata": {},
   "source": [
    "### Task J: 10 points\n",
    "\n",
    "Perform task D through I except task G using FP-Growth algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "dc82b3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      support                         itemsets\n",
      "0    0.157923                     (whole milk)\n",
      "1    0.085879                         (yogurt)\n",
      "2    0.060349                        (sausage)\n",
      "3    0.009490            (semi-finished bread)\n",
      "4    0.051728                         (pastry)\n",
      "..        ...                              ...\n",
      "745  0.001403            (chewing gum, yogurt)\n",
      "746  0.001069  (other vegetables, chewing gum)\n",
      "747  0.001002              (soda, chewing gum)\n",
      "748  0.001069              (pasta, whole milk)\n",
      "749  0.001002  (seasonal products, rolls/buns)\n",
      "\n",
      "[750 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Task D\n",
    "# Apply the FP-Growth algorithm with a support threshold of 0.001.\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "support_threshold = 0.001\n",
    "frequent_itemsets_fp = fpgrowth(transformed_data_f.drop(['Member_number', 'Date'], axis=1), min_support=support_threshold, use_colnames=True)\n",
    "print(frequent_itemsets_fp)\n",
    "\n",
    "fpgrowth_association_rules = association_rules(frequent_itemsets_fp, metric='lift',min_threshold=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c8b37bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              antecedents            consequents  antecedent support  \\\n",
      "11   (whole milk, yogurt)              (sausage)            0.011161   \n",
      "14              (sausage)   (whole milk, yogurt)            0.060349   \n",
      "12  (sausage, whole milk)               (yogurt)            0.008955   \n",
      "13               (yogurt)  (sausage, whole milk)            0.085879   \n",
      "94  (specialty chocolate)         (citrus fruit)            0.015973   \n",
      "\n",
      "    consequent support   support  confidence      lift  leverage  conviction  \\\n",
      "11            0.060349  0.001470    0.131737  2.182917  0.000797    1.082219   \n",
      "14            0.011161  0.001470    0.024363  2.182917  0.000797    1.013532   \n",
      "12            0.085879  0.001470    0.164179  1.911760  0.000701    1.093681   \n",
      "13            0.008955  0.001470    0.017121  1.911760  0.000701    1.008307   \n",
      "94            0.053131  0.001403    0.087866  1.653762  0.000555    1.038081   \n",
      "\n",
      "    zhangs_metric  \n",
      "11       0.548014  \n",
      "14       0.576701  \n",
      "12       0.481231  \n",
      "13       0.521727  \n",
      "94       0.401735  \n"
     ]
    }
   ],
   "source": [
    "#Task e\n",
    "# Print the top 5 association rules based on the lift metric and a threshold of 1, according to the support value.\n",
    "# Sorting the rules in descending order based on the 'lift' parameter\n",
    "top_5_association_rules = fpgrowth_association_rules.nlargest(5, 'lift')\n",
    "top_5_association_rules.sort_values(by='support', ascending=False, inplace=True)\n",
    "print(top_5_association_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8164ee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 antecedents              consequents  antecedent support  \\\n",
      "11      (whole milk, yogurt)                (sausage)            0.011161   \n",
      "14                 (sausage)     (whole milk, yogurt)            0.060349   \n",
      "12     (sausage, whole milk)                 (yogurt)            0.008955   \n",
      "13                  (yogurt)    (sausage, whole milk)            0.085879   \n",
      "94     (specialty chocolate)           (citrus fruit)            0.015973   \n",
      "..                       ...                      ...                 ...   \n",
      "169                 (grapes)                   (soda)            0.014436   \n",
      "59                    (beef)           (citrus fruit)            0.033950   \n",
      "58            (citrus fruit)                   (beef)            0.053131   \n",
      "201  (fruit/vegetable juice)             (rolls/buns)            0.034017   \n",
      "200             (rolls/buns)  (fruit/vegetable juice)            0.110005   \n",
      "\n",
      "     consequent support   support  confidence      lift      leverage  \\\n",
      "11             0.060349  0.001470    0.131737  2.182917  7.967480e-04   \n",
      "14             0.011161  0.001470    0.024363  2.182917  7.967480e-04   \n",
      "12             0.085879  0.001470    0.164179  1.911760  7.012151e-04   \n",
      "13             0.008955  0.001470    0.017121  1.911760  7.012151e-04   \n",
      "94             0.053131  0.001403    0.087866  1.653762  5.548137e-04   \n",
      "..                  ...       ...         ...       ...           ...   \n",
      "169            0.097106  0.001403    0.097222  1.001195  1.674919e-06   \n",
      "59             0.053131  0.001804    0.053150  1.000349  6.297697e-07   \n",
      "58             0.033950  0.001804    0.033962  1.000349  6.297697e-07   \n",
      "201            0.110005  0.003743    0.110020  1.000136  5.091755e-07   \n",
      "200            0.034017  0.003743    0.034022  1.000136  5.091755e-07   \n",
      "\n",
      "     conviction  zhangs_metric  \n",
      "11     1.082219       0.548014  \n",
      "14     1.013532       0.576701  \n",
      "12     1.093681       0.481231  \n",
      "13     1.008307       0.521727  \n",
      "94     1.038081       0.401735  \n",
      "..          ...            ...  \n",
      "169    1.000129       0.001211  \n",
      "59     1.000020       0.000361  \n",
      "58     1.000012       0.000369  \n",
      "201    1.000017       0.000141  \n",
      "200    1.000005       0.000153  \n",
      "\n",
      "[240 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Task f\n",
    "# Store the association rules from top to bottom, sorted by the lift parameter, and store them in a variable.\n",
    "\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "# Sorting association rules by lift parameter in descending order\n",
    "sorted_rules_by_lift = fpgrowth_association_rules.sort_values(by='lift', ascending=False)\n",
    "print(sorted_rules_by_lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "1a3146eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended items for 'sausage':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'whole milk', 'yogurt'},\n",
       " {'yogurt'},\n",
       " {'whole milk'},\n",
       " {'beverages'},\n",
       " {'soda', 'whole milk'}]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TaskH\n",
    "# Print the top 5 recommended items for the product 'sausage'.\n",
    "\n",
    "product_name = 'sausage'\n",
    "top_recommendations = get_top_recommendations(sorted_rules_by_lift, product_name)\n",
    "\n",
    "print(f\"Top 5 recommended items for '{product_name}':\")\n",
    "top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1468a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended items for 'sausage':\n",
      "[{'yogurt'}, {'soda'}]\n"
     ]
    }
   ],
   "source": [
    "#Task I\n",
    "# Print the top 5 recommended items for the product 'sausage' with a support threshold of 0.005.\n",
    "# Generate association rules from frequent itemsets\n",
    "association_rules_df = association_rules(frequent_itemsets_f, metric=\"lift\", min_threshold=1)\n",
    "sorted_rules_by_lift = association_rules_df.sort_values(by='lift', ascending=False)\n",
    "\n",
    "product_name = 'sausage'\n",
    "top_5_recommended_items = get_top_recommendations(sorted_rules_by_lift, product_name)\n",
    "\n",
    "print(f\"Top 5 recommended items for 'sausage':\")\n",
    "print(top_5_recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c619c",
   "metadata": {},
   "source": [
    "References:\n",
    "    \n",
    "https://medium.com/@gabrielreversi/association-rules-the-fp-growth-algorithm-baaaa1263fea\n",
    "https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/fpgrowth/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ecc04",
   "metadata": {},
   "source": [
    "### Task K: 8 points\n",
    "\n",
    "Print Top 3 recommendations for below products using Apriori with 0.0015 support\n",
    "- citrus fruit\n",
    "- whole milk\n",
    "- soda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d503e536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommendations for citrus fruits are as follows\n",
      " [{'frozen vegetables'}, {'butter'}, {'yogurt'}]\n",
      "Top 3 recommendations for whole milk are as follows\n",
      " [{'semi-finished bread'}, {'ham'}]\n",
      "Top 3 recommendations for soda are as follows\n",
      " [{'oil'}, {'beverages'}, {'sausage'}]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori as apr\n",
    "\n",
    "def top_recommendations_with_support_threshold(top_rules_df, product_name, support_threshold , top_n):\n",
    "    \n",
    "    # Filtering association rules where the product_name is present in the antecedents\n",
    "    filtered_rules = top_rules_df[top_rules_df['antecedents'].apply(\n",
    "        lambda x: product_name in x)]\n",
    "\n",
    "    # Filtering association rules that have a support >= the support threshold\n",
    "    filtered_rules = filtered_rules[filtered_rules['support'] >= support_threshold]\n",
    "\n",
    "    # Sorting rules in decreasing order based on lift\n",
    "    sorted_rules = filtered_rules.sort_values('lift', ascending=False)\n",
    "\n",
    "    # Fetching top_n consequents\n",
    "    top_n_consequents = sorted_rules['consequents'].head(top_n)\n",
    "    top_n_consequents = [set(items) for items in top_n_consequents]\n",
    "    return top_n_consequents\n",
    " \n",
    "print(\"Top 3 recommendations for citrus fruits are as follows\\n\",top_recommendations_with_support_threshold(top_association_rules, 'citrus fruit', 0.0015, 3))\n",
    "print(\"Top 3 recommendations for whole milk are as follows\\n\",top_recommendations_with_support_threshold(top_association_rules, 'whole milk', 0.0015, 3))\n",
    "print(\"Top 3 recommendations for soda are as follows\\n\",top_recommendations_with_support_threshold(top_association_rules, 'soda', 0.0015, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c661430",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://medium.com/analytics-vidhya/association-analysis-in-python-2b955d0180c\n",
    "https://efficient-apriori.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3ce9f",
   "metadata": {},
   "source": [
    "### Task L: 8 points\n",
    "\n",
    "Print Top 3 recommendations for below products using FP-Growth algorithm with 0.0015 support\n",
    "- canned beer\n",
    "- yogurt\n",
    "- pastry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3b70a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommendations for citrus fruits are as follows\n",
      " [{'white bread'}, {'brown bread'}, {'newspapers'}]\n",
      "Top 3 recommendations for whole milk are as follows\n",
      " [{'sausage'}, {'citrus fruit'}]\n",
      "Top 3 recommendations for soda are as follows\n",
      " [{'napkins'}, {'brown bread'}, {'sausage'}]\n"
     ]
    }
   ],
   "source": [
    "# Using FP-Growth \n",
    "print(\"Top 3 recommendations for citrus fruits are as follows\\n\",top_recommendations_with_support_threshold(top_association_rules_fp, 'canned beer', 0.0015, 3))\n",
    "print(\"Top 3 recommendations for whole milk are as follows\\n\",top_recommendations_with_support_threshold(top_association_rules_fp, 'yogurt', 0.0015, 3))\n",
    "print(\"Top 3 recommendations for soda are as follows\\n\",top_recommendations_with_support_threshold(top_association_rules_fp, 'pastry', 0.0015, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e820c",
   "metadata": {},
   "source": [
    "References:\n",
    "    \n",
    "https://medium.com/@gabrielreversi/association-rules-the-fp-growth-algorithm-baaaa1263fea\n",
    "https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/fpgrowth/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8db21a",
   "metadata": {},
   "source": [
    "### Task M: 20 points\n",
    "\n",
    "Submit a document showing your solution for below problem.\n",
    "\n",
    "For the data on apriori image in the folder, apply apriori algorithm by\n",
    "\n",
    "- Computing the support for each individual item\n",
    "- Use 7 as the minimum support.\n",
    "- Generate Association Rules and compute confidence \n",
    "- use min confidence as 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d9883",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://medium.com/analytics-vidhya/association-analysis-in-python-2b955d0180c\n",
    "https://efficient-apriori.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c8d9f",
   "metadata": {},
   "source": [
    "### Programming Assignment Details\n",
    "\n",
    "1. If using any resource (books, internet), please make sure that you cite it within that cell.\n",
    "2. Do not rename the dataset_files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea28bf",
   "metadata": {},
   "source": [
    "###  Submission details\n",
    "Fill your name and ID in the jupyter notebook for each group member in the following format:\n",
    "\n",
    "1. First Student Name and ID: ABC 1001XXXXXX\n",
    "2. Second Student Name and ID: DEF 1002XXXXXX\n",
    "3. Third Student Name and ID: GHI 1003XXXXXX\n",
    "\n",
    "Name your submission files:\n",
    "\n",
    "yourLastName_Last4digitsofyourID.ipynb\n",
    "\n",
    "EG: abc_1234_def_5678_xyz3819_python.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecd9370",
   "metadata": {},
   "source": [
    "### NOTE: Only one team member will submit the file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
